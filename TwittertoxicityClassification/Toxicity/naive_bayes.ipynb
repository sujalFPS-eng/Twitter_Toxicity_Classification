{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "\n",
    "import config\n",
    "import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/colan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mINFO:\u001b[0m Loading Training Data\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Loading Training Data\")\n",
    "\n",
    "# use a low n-rows when testing else don't set it\n",
    "df = pd.read_csv(config.TRAIN_PATH, header=0, nrows=1000, usecols=['target', 'comment_text'])\n",
    "# df = pd.read_csv(config.TRAIN_PATH, header=0, usecols=['target', 'comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I call dibs on the Tonya Harding pic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>This is just freaking sad. Another great place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is a test comment (trying out the new Civ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is a test comment (trying out the new Civ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Test comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                       comment_text\n",
       "0    0.000000  This is so cool. It's like, 'would you want yo...\n",
       "1    0.000000  Thank you!! This would make my life a lot less...\n",
       "2    0.000000  This is such an urgent design problem; kudos t...\n",
       "3    0.000000  Is this something I'll be able to install on m...\n",
       "4    0.893617               haha you guys are a bunch of losers.\n",
       "..        ...                                                ...\n",
       "995  0.000000               I call dibs on the Tonya Harding pic\n",
       "996  0.629630  This is just freaking sad. Another great place...\n",
       "997  0.000000  This is a test comment (trying out the new Civ...\n",
       "998  0.000000  This is a test comment (trying out the new Civ...\n",
       "999  0.000000                                       Test comment\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying Targets\n",
    "\n",
    "For this sample we are going to only use the input text and have it guess a sample label. To get the sample label we are going to create 3 intermediaries for the calculated toxicity target betwee 0 and 1.\n",
    "\n",
    "* 0.00-0.20 -> not toxic\n",
    "* 0.21-0.60 -> mildly toxic\n",
    "* 0.61-1.00 -> toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df['target'].apply(lambda t: 'not_toxic' if t <= 0.2 else 'mildly_toxic' if t <= 0.6 else 'toxic')\n",
    "df.update(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_toxic       893\n",
       "mildly_toxic     82\n",
       "toxic            25\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedRandomClassifier():\n",
    "    def __init__(self, counts):\n",
    "        total = float(sum([count for count in counts]))\n",
    "        \n",
    "        self.probabilities = []\n",
    "        self.probabilities.append(counts.not_toxic / total)\n",
    "        self.probabilities.append(counts.mildly_toxic / total)        \n",
    "        self.probabilities.append(counts.toxic / total)  \n",
    "        \n",
    "        self.classes = ['not_toxic', 'mildly_toxic', 'toxic']\n",
    "        \n",
    "    def predict(self):\n",
    "        # https://stackoverflow.com/questions/13343347/randomizing-two-lists-and-maintaining-order-in-python\n",
    "        combined = list(zip(self.probabilities, self.classes))\n",
    "        random.shuffle(combined)\n",
    "        self.probabilities, self.classes = zip(*combined)\n",
    "        \n",
    "        # run until a class is found\n",
    "        probability_to_reach = random.random()\n",
    "        current_probability = 0\n",
    "        index = 0\n",
    "        \n",
    "        while True:\n",
    "            current_probability += self.probabilities[index]\n",
    "            \n",
    "            if current_probability < probability_to_reach:\n",
    "                break\n",
    "                \n",
    "            index += 1\n",
    "            \n",
    "            if index == len(self.classes):\n",
    "                index -= 1\n",
    "                break\n",
    "            \n",
    "        return self.classes[index]\n",
    "    \n",
    "    def accuracy(self, nltk_expected_input):\n",
    "        '''\n",
    "        [(input, target_class), ...]\n",
    "        '''\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for element in nltk_expected_input:\n",
    "            if self.predict() == element[1]:\n",
    "                correct += 1\n",
    "            \n",
    "            total += 1\n",
    "            \n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomClassifier():\n",
    "    def __init__(self):\n",
    "        self.classes = ['not_toxic', 'mildly_toxic', 'toxic']\n",
    "\n",
    "    def predict(self):\n",
    "        return random.choice(self.classes)\n",
    "\n",
    "    def accuracy(self, nltk_expected_input):\n",
    "        '''\n",
    "        [(input, target_class), ...]\n",
    "        '''\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for element in nltk_expected_input:\n",
    "            if self.predict() == element[1]:\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_random_classifier = WeightedRandomClassifier(df.target.value_counts())\n",
    "random_classifier = RandomClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df['comment_text'].apply(lambda comment: comment.lower())\n",
    "df.update(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>not_toxic</td>\n",
       "      <td>this is so cool. it's like, 'would you want yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>not_toxic</td>\n",
       "      <td>thank you!! this would make my life a lot less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>not_toxic</td>\n",
       "      <td>this is such an urgent design problem; kudos t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>not_toxic</td>\n",
       "      <td>is this something i'll be able to install on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>toxic</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>not_toxic</td>\n",
       "      <td>i call dibs on the tonya harding pic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>toxic</td>\n",
       "      <td>this is just freaking sad. another great place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>not_toxic</td>\n",
       "      <td>this is a test comment (trying out the new civ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>not_toxic</td>\n",
       "      <td>this is a test comment (trying out the new civ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>not_toxic</td>\n",
       "      <td>test comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                       comment_text\n",
       "0    not_toxic  this is so cool. it's like, 'would you want yo...\n",
       "1    not_toxic  thank you!! this would make my life a lot less...\n",
       "2    not_toxic  this is such an urgent design problem; kudos t...\n",
       "3    not_toxic  is this something i'll be able to install on m...\n",
       "4        toxic               haha you guys are a bunch of losers.\n",
       "..         ...                                                ...\n",
       "995  not_toxic               i call dibs on the tonya harding pic\n",
       "996      toxic  this is just freaking sad. another great place...\n",
       "997  not_toxic  this is a test comment (trying out the new civ...\n",
       "998  not_toxic  this is a test comment (trying out the new civ...\n",
       "999  not_toxic                                       test comment\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting\n",
    "\n",
    "We split the data so we can estimate the performace of our algorithm. You can set the switch value below to decide the split. Default is to 0.8 where 80% of the training is trained on and 20% is tested on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_percentage = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mINFO:\u001b[0m Train Data Size: 800\n",
      "\u001b[94mINFO:\u001b[0m Test Data Size: 200\n"
     ]
    }
   ],
   "source": [
    "training_set, testing_set = train_test_split(df, test_size = 1.0 - split_percentage)\n",
    "\n",
    "log.info(f'Train Data Size: {len(training_set)}')\n",
    "log.info(f'Test Data Size: {len(testing_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting and Bag of Words\n",
    "\n",
    "We'll use the 1000 most occurring words for our bag of words in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "training_data = []\n",
    "\n",
    "word_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training_set.to_dict()\n",
    "test = testing_set.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a4c5a8fb3d4017bb884f4bb2ad186a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "\n",
    "for key in tqdm_notebook(train['comment_text']):\n",
    "    tokens = tweet_tokenizer.tokenize(train['comment_text'][key])\n",
    "    train['comment_text'][key] = tokens\n",
    "    \n",
    "    c = Counter(tokens)\n",
    "    word_counts.update(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = word_counts.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mINFO:\u001b[0m training set updates\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2516de9701de4a93a662357131c82a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log.info('training set updates')\n",
    "\n",
    "for key in tqdm_notebook(train['comment_text']):\n",
    "    tokenized_sentence = train['comment_text'][key]\n",
    "    bow = {}\n",
    "    \n",
    "    for word in most_common_words:\n",
    "        word = word[0]\n",
    "        \n",
    "        if word in tokenized_sentence:\n",
    "            bow[word] = tokenized_sentence.count(word)\n",
    "        else:\n",
    "            bow[word] = 0\n",
    "            \n",
    "    train['comment_text'][key] = bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mINFO:\u001b[0m testing set updates\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ef1b26788d418fb538f8505c972caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log.info('testing set updates')\n",
    "\n",
    "for key in tqdm_notebook(test['comment_text']):\n",
    "    tokenized_sentence = tweet_tokenizer.tokenize(test['comment_text'][key])\n",
    "    bow = {}\n",
    "    \n",
    "    for word in most_common_words:\n",
    "        word = word[0]\n",
    "        \n",
    "        if word in tokenized_sentence:\n",
    "            bow[word] = tokenized_sentence.count(word)\n",
    "        else:\n",
    "            bow[word] = 0\n",
    "\n",
    "    test['comment_text'][key] = bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mINFO:\u001b[0m formatting training data for NLTK\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f0627dc9ac4fdf9e20324bed56109f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log.info('formatting training data for NLTK')\n",
    "\n",
    "final_training_set = []\n",
    "for key in tqdm_notebook(train['target']):\n",
    "    final_training_set.append((train['comment_text'][key], train['target'][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mINFO:\u001b[0m formatting testing data for nltk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79336b29130f48b5b6817f1a54060487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log.info('formatting testing data for nltk')\n",
    "\n",
    "final_testing_set = []\n",
    "for key in tqdm_notebook(test['target']):\n",
    "    final_testing_set.append((test['comment_text'][key], test['target'][key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = nltk.NaiveBayesClassifier.train(final_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Classifier: 0.33\n",
      "Weighted Random Classifier: 0.12\n",
      "Niave Bayes Accuracy: 0.795\n",
      "Precision: not implemented\n",
      "Recall: not implemented\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Classifier: {random_classifier.accuracy(final_testing_set)}')\n",
    "print(f'Weighted Random Classifier: {weighted_random_classifier.accuracy(final_testing_set)}')\n",
    "print(f'Niave Bayes Accuracy: {nltk.classify.accuracy(naive_bayes_classifier, final_testing_set)}')\n",
    "print(f'Precision: not implemented')\n",
    "print(f'Recall: not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   bunch = 1               toxic : not_to =     75.6 : 1.0\n",
      "                    guys = 1               toxic : not_to =     32.4 : 1.0\n",
      "                   going = 2               toxic : not_to =     31.7 : 1.0\n",
      "                    want = 3               toxic : not_to =     31.0 : 1.0\n",
      "                   after = 2               toxic : not_to =     31.0 : 1.0\n",
      "                       * = 1               toxic : not_to =     30.4 : 1.0\n",
      "                     law = 2               toxic : not_to =     29.8 : 1.0\n",
      "                     few = 2               toxic : not_to =     19.0 : 1.0\n",
      "                       ; = 2               toxic : not_to =     18.6 : 1.0\n",
      "                   mayor = 2              mildly : not_to =     17.4 : 1.0\n",
      "                  threat = 1              mildly : not_to =     17.4 : 1.0\n",
      "                   armed = 1              mildly : not_to =     15.0 : 1.0\n",
      "                   total = 1               toxic : not_to =     13.9 : 1.0\n",
      "                   woman = 1               toxic : not_to =     13.9 : 1.0\n",
      "                     gun = 1               toxic : not_to =     13.6 : 1.0\n",
      "                  report = 1               toxic : not_to =     13.6 : 1.0\n",
      "             enforcement = 2               toxic : not_to =     13.6 : 1.0\n",
      "                    kill = 1               toxic : not_to =     13.6 : 1.0\n",
      "                    both = 2               toxic : not_to =     13.6 : 1.0\n",
      "                   lived = 1              mildly : not_to =     13.5 : 1.0\n",
      "                   video = 1               toxic : not_to =     13.3 : 1.0\n",
      "                      or = 3               toxic : not_to =     13.0 : 1.0\n",
      "                   white = 1              mildly : not_to =     12.6 : 1.0\n",
      "                    call = 1               toxic : not_to =     12.5 : 1.0\n",
      "                  create = 1               toxic : not_to =     10.8 : 1.0\n",
      "               dangerous = 1               toxic : not_to =     10.8 : 1.0\n",
      "                    room = 1               toxic : not_to =     10.8 : 1.0\n",
      "                  trying = 2               toxic : not_to =     10.6 : 1.0\n",
      "                    ways = 1               toxic : not_to =     10.6 : 1.0\n",
      "                   heart = 1              mildly : not_to =     10.5 : 1.0\n",
      "                  trolls = 1              mildly : not_to =     10.5 : 1.0\n",
      "                problems = 2              mildly : not_to =     10.4 : 1.0\n",
      "                   burns = 2              mildly : not_to =     10.4 : 1.0\n",
      "                    lies = 1              mildly : not_to =     10.4 : 1.0\n",
      "                     son = 1              mildly : not_to =     10.4 : 1.0\n",
      "                response = 2              mildly : not_to =     10.4 : 1.0\n",
      "                   angry = 2              mildly : not_to =     10.4 : 1.0\n",
      "                    thom = 2              mildly : not_to =     10.4 : 1.0\n",
      "                    come = 2              mildly : not_to =     10.4 : 1.0\n",
      "                  forget = 1              mildly : not_to =     10.4 : 1.0\n",
      "                   agree = 2              mildly : not_to =     10.4 : 1.0\n",
      "                     day = 2              mildly : not_to =     10.4 : 1.0\n",
      "                       # = 2              mildly : not_to =     10.4 : 1.0\n",
      "                    laws = 2              mildly : not_to =     10.4 : 1.0\n",
      "                   media = 2              mildly : not_to =     10.4 : 1.0\n",
      "                    such = 2              mildly : not_to =     10.4 : 1.0\n",
      "                    name = 2              mildly : not_to =     10.4 : 1.0\n",
      "                   sites = 1              mildly : not_to =     10.4 : 1.0\n",
      "                   needs = 2              mildly : not_to =     10.4 : 1.0\n",
      "                    hold = 1              mildly : not_to =     10.4 : 1.0\n",
      "                   crime = 2              mildly : not_to =     10.4 : 1.0\n",
      "                      an = 3              mildly : not_to =     10.3 : 1.0\n",
      "                   right = 2              mildly : not_to =     10.3 : 1.0\n",
      "                   every = 2              mildly : not_to =     10.3 : 1.0\n",
      "                    help = 2              mildly : not_to =     10.3 : 1.0\n",
      "                   trust = 2              mildly : not_to =     10.3 : 1.0\n",
      "                       & = 2              mildly : not_to =     10.3 : 1.0\n",
      "                       ” = 2              mildly : not_to =     10.3 : 1.0\n",
      "                  equity = 1              mildly : not_to =     10.3 : 1.0\n",
      "                       ' = 6              mildly : not_to =     10.3 : 1.0\n",
      "                    here = 3              mildly : not_to =     10.3 : 1.0\n",
      "                   their = 4              mildly : not_to =     10.2 : 1.0\n",
      "                    them = 4              mildly : not_to =     10.2 : 1.0\n",
      "                       ? = 5              mildly : not_to =     10.1 : 1.0\n",
      "                    have = 4              mildly : not_to =     10.1 : 1.0\n",
      "                     was = 6              mildly : not_to =     10.1 : 1.0\n",
      "                     for = 6              mildly : not_to =     10.1 : 1.0\n",
      "                     are = 5              mildly : not_to =     10.1 : 1.0\n",
      "                       \" = 12             mildly : not_to =      9.8 : 1.0\n",
      "                    yeah = 1               toxic : not_to =      8.8 : 1.0\n",
      "                   stand = 1               toxic : not_to =      8.8 : 1.0\n",
      "                 details = 1               toxic : not_to =      8.8 : 1.0\n",
      "                   shows = 1               toxic : not_to =      8.8 : 1.0\n",
      "                  killed = 1               toxic : not_to =      8.8 : 1.0\n",
      "                decision = 1               toxic : not_to =      8.6 : 1.0\n",
      "               available = 1               toxic : not_to =      8.6 : 1.0\n",
      "                    laws = 1               toxic : not_to =      8.6 : 1.0\n",
      "                 opinion = 1               toxic : not_to =      8.6 : 1.0\n",
      "                   world = 1               toxic : not_to =      8.3 : 1.0\n",
      "                    feds = 1              mildly : not_to =      8.2 : 1.0\n",
      "                  oregon = 2               toxic : not_to =      8.1 : 1.0\n",
      "                     nor = 1              mildly : not_to =      8.1 : 1.0\n",
      "                  raised = 1              mildly : not_to =      8.1 : 1.0\n",
      "                  follow = 1              mildly : not_to =      8.1 : 1.0\n",
      "                    they = 4              mildly : not_to =      7.9 : 1.0\n",
      "                       : = 1               toxic : mildly =      7.6 : 1.0\n",
      "                  entire = 1               toxic : not_to =      7.5 : 1.0\n",
      "                  common = 1               toxic : not_to =      7.5 : 1.0\n",
      "                 finally = 1               toxic : not_to =      7.5 : 1.0\n",
      "                    full = 1               toxic : not_to =      7.5 : 1.0\n",
      "                  recent = 1               toxic : not_to =      7.5 : 1.0\n",
      "                  cannot = 1               toxic : not_to =      7.5 : 1.0\n",
      "                    spot = 1               toxic : not_to =      7.5 : 1.0\n",
      "                   spend = 1               toxic : not_to =      7.5 : 1.0\n",
      "                   major = 1               toxic : not_to =      7.5 : 1.0\n",
      "                  author = 1               toxic : not_to =      7.5 : 1.0\n",
      "                militias = 1              mildly : not_to =      7.4 : 1.0\n",
      "                    need = 2              mildly : not_to =      7.4 : 1.0\n",
      "                       t = 2              mildly : not_to =      7.4 : 1.0\n",
      "                    held = 1              mildly : not_to =      7.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier.show_most_informative_features(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
